{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "216c654b-ed9a-4089-842e-16477626b522",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-23T19:56:22.434767Z",
     "iopub.status.busy": "2022-11-23T19:56:22.434541Z",
     "iopub.status.idle": "2022-11-23T19:56:24.027098Z",
     "shell.execute_reply": "2022-11-23T19:56:24.026564Z",
     "shell.execute_reply.started": "2022-11-23T19:56:22.434748Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from -r requirements.txt (line 1)) (1.23.5)\n",
      "Requirement already satisfied: hyperopt in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from -r requirements.txt (line 2)) (0.2.7)\n",
      "Requirement already satisfied: catboost in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from -r requirements.txt (line 3)) (1.1.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from -r requirements.txt (line 4)) (1.5.2)\n",
      "Requirement already satisfied: geopy in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from -r requirements.txt (line 5)) (2.3.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from -r requirements.txt (line 6)) (3.6.2)\n",
      "Requirement already satisfied: shap in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from -r requirements.txt (line 7)) (0.41.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from -r requirements.txt (line 8)) (1.9.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from -r requirements.txt (line 9)) (4.64.1)\n",
      "Requirement already satisfied: torch in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from -r requirements.txt (line 10)) (1.13.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from -r requirements.txt (line 11)) (0.14.0)\n",
      "Requirement already satisfied: albumentations in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from -r requirements.txt (line 12)) (1.3.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from -r requirements.txt (line 13)) (4.6.0.66)\n",
      "Requirement already satisfied: seaborn in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from -r requirements.txt (line 14)) (0.12.1)\n",
      "Requirement already satisfied: typing in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from -r requirements.txt (line 15)) (3.7.4.3)\n",
      "Requirement already satisfied: six in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from hyperopt->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from hyperopt->-r requirements.txt (line 2)) (2.2.0)\n",
      "Requirement already satisfied: future in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from hyperopt->-r requirements.txt (line 2)) (0.18.2)\n",
      "Requirement already satisfied: py4j in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from hyperopt->-r requirements.txt (line 2)) (0.10.9.7)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from hyperopt->-r requirements.txt (line 2)) (2.8.8)\n",
      "Requirement already satisfied: plotly in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from catboost->-r requirements.txt (line 3)) (5.11.0)\n",
      "Requirement already satisfied: graphviz in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from catboost->-r requirements.txt (line 3)) (0.20.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->-r requirements.txt (line 4)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->-r requirements.txt (line 4)) (2022.6)\n",
      "Requirement already satisfied: geographiclib<3,>=1.52 in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from geopy->-r requirements.txt (line 5)) (2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->-r requirements.txt (line 6)) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->-r requirements.txt (line 6)) (1.4.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->-r requirements.txt (line 6)) (1.0.6)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->-r requirements.txt (line 6)) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->-r requirements.txt (line 6)) (9.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->-r requirements.txt (line 6)) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->-r requirements.txt (line 6)) (4.38.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from shap->-r requirements.txt (line 7)) (1.1.3)\n",
      "Requirement already satisfied: slicer==0.0.7 in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from shap->-r requirements.txt (line 7)) (0.0.7)\n",
      "Requirement already satisfied: numba in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from shap->-r requirements.txt (line 7)) (0.56.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm->-r requirements.txt (line 9)) (0.4.6)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch->-r requirements.txt (line 10)) (4.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchvision->-r requirements.txt (line 11)) (2.28.1)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from albumentations->-r requirements.txt (line 12)) (0.19.3)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from albumentations->-r requirements.txt (line 12)) (4.6.0.66)\n",
      "Requirement already satisfied: qudida>=0.0.4 in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from albumentations->-r requirements.txt (line 12)) (0.0.4)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from albumentations->-r requirements.txt (line 12)) (6.0)\n",
      "Requirement already satisfied: imageio>=2.4.1 in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-image>=0.16.1->albumentations->-r requirements.txt (line 12)) (2.22.4)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-image>=0.16.1->albumentations->-r requirements.txt (line 12)) (2022.10.10)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-image>=0.16.1->albumentations->-r requirements.txt (line 12)) (1.4.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->shap->-r requirements.txt (line 7)) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->shap->-r requirements.txt (line 7)) (1.2.0)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from numba->shap->-r requirements.txt (line 7)) (0.39.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from numba->shap->-r requirements.txt (line 7)) (58.1.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from plotly->catboost->-r requirements.txt (line 3)) (8.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->torchvision->-r requirements.txt (line 11)) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->torchvision->-r requirements.txt (line 11)) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->torchvision->-r requirements.txt (line 11)) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\fedor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->torchvision->-r requirements.txt (line 11)) (3.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c15afc4b-482e-4622-bfc7-86240db08c00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T09:01:43.363975Z",
     "iopub.status.busy": "2022-11-24T09:01:43.363782Z",
     "iopub.status.idle": "2022-11-24T09:01:44.319478Z",
     "shell.execute_reply": "2022-11-24T09:01:44.318945Z",
     "shell.execute_reply.started": "2022-11-24T09:01:43.363962Z"
    },
    "id": "ouwPzoapsv4V",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "import albumentations as A\n",
    "import cv2\n",
    "from tqdm.auto import tqdm\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.cuda.amp import GradScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "451783ab-3c9b-4f22-ac7c-74f99971a6b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T09:01:42.715179Z",
     "iopub.status.busy": "2022-11-24T09:01:42.714882Z",
     "iopub.status.idle": "2022-11-24T09:01:43.362885Z",
     "shell.execute_reply": "2022-11-24T09:01:43.362306Z",
     "shell.execute_reply.started": "2022-11-24T09:01:42.715157Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9766ea04-b291-4dc7-88f5-1dca816c528c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T09:01:44.320246Z",
     "iopub.status.busy": "2022-11-24T09:01:44.320013Z",
     "iopub.status.idle": "2022-11-24T09:01:44.465185Z",
     "shell.execute_reply": "2022-11-24T09:01:44.464642Z",
     "shell.execute_reply.started": "2022-11-24T09:01:44.320232Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!tar -xf car_color_dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c17e1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17d951dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = A.Compose([\n",
    "                        A.LongestMaxSize(size),\n",
    "                        A.PadIfNeeded(size, size),\n",
    "                        A.CenterCrop(224, 224),\n",
    "                        A.Normalize(),\n",
    "                        ToTensorV2(),\n",
    "])\n",
    "class CarsDatasetTest(torch.utils.data.Dataset):\n",
    "    def __init__(self, path_to_data, transform=False, train=False):\n",
    "        self.path_to_data = path_to_data\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self._get_data_from_path()\n",
    "        if self.transform:\n",
    "            self._add_augmentations()\n",
    "        #self.data = np.array(self.data)\n",
    "\n",
    "    def _get_data_from_path(self):\n",
    "            for img in tqdm(os.listdir(self.path_to_data)):\n",
    "                if img[0]!='.':\n",
    "                    img = cv2.imread(os.path.join(self.path_to_data, img))\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                    label = 0\n",
    "                    self.data.append(img)\n",
    "                    self.labels.append(label)\n",
    "\n",
    "    def _add_augmentations(self):\n",
    "        data = self.data.copy()\n",
    "        del self.data\n",
    "        self.data = []\n",
    "        for img in tqdm(data):\n",
    "            transformed = self.transform(image=img)\n",
    "            img_tensor = transformed['image']\n",
    "            self.data.append(img_tensor)\n",
    "        del data\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed96067",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_test = './public_test'\n",
    "test_dataset = CarsDatasetTest(path_to_test, transform=test_transform)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b8b0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_predict(model, val_dataloader, criterion=None,device=\"cuda:0\"):\n",
    "    model.eval()\n",
    "    predicted_classes = torch.tensor([])\n",
    "    total_loss = 0\n",
    "    n_batchs = 0\n",
    "    first = True\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_dataloader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            #y_preds = model(X_batch)\n",
    "            #total_loss += criterion(y_preds, y_batch)\n",
    "            #y_batch = y_batch.cpu()\n",
    "            if first:\n",
    "                predicted_probas = F.softmax(model(X_batch), dim=1).cpu()\n",
    "                first = False\n",
    "            else:\n",
    "                probas = F.softmax(model(X_batch), dim=1).cpu()\n",
    "                predicted_probas = torch.cat((predicted_probas, probas), dim=0)\n",
    "    return predicted_probas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87751514-e6cb-43de-aaaa-93400d7d33a8",
   "metadata": {},
   "source": [
    "# Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00553fc1-1561-4cec-8e1b-aaf7596e48c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T08:20:16.411602Z",
     "iopub.status.busy": "2022-11-24T08:20:16.411207Z",
     "iopub.status.idle": "2022-11-24T08:20:21.189120Z",
     "shell.execute_reply": "2022-11-24T08:20:21.188704Z",
     "shell.execute_reply.started": "2022-11-24T08:20:16.411586Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fedyans_probas = torch.zeros((len(test_dataset.data), 1000))\n",
    "for  i in range(6):\n",
    "    with open(f'./models_1000/model_{i}.pkl', 'rb') as f:\n",
    "        eff  = pickle.load(f)\n",
    "        fedyans_probas += cv_predict(eff, test_dataloader)\n",
    "fedyans_probas /= 6\n",
    "fedyans_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6785e5f-4745-4a69-921f-d60a93eddf61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T08:20:21.190348Z",
     "iopub.status.busy": "2022-11-24T08:20:21.189924Z",
     "iopub.status.idle": "2022-11-24T08:20:21.192487Z",
     "shell.execute_reply": "2022-11-24T08:20:21.192122Z",
     "shell.execute_reply.started": "2022-11-24T08:20:21.190333Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fedyans_probas = fedyans_probas[:, :11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "163b9e66-d445-4da3-a6e7-d54b1b46b85d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T08:20:21.197171Z",
     "iopub.status.busy": "2022-11-24T08:20:21.197038Z",
     "iopub.status.idle": "2022-11-24T08:20:41.070390Z",
     "shell.execute_reply": "2022-11-24T08:20:41.069924Z",
     "shell.execute_reply.started": "2022-11-24T08:20:21.197158Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_probas_ef = torch.zeros((len(test_dataset.data), 11))\n",
    "for  i in range(5):\n",
    "    with open(f'./models_1/model_{i}.pkl', 'rb') as f:\n",
    "        eff  = pickle.load(f)\n",
    "        total_probas_ef += cv_predict(eff, test_dataloader)\n",
    "total_probas_ef /= 5\n",
    "total_probas_res = torch.zeros((len(test_dataset.data), 11))\n",
    "for  i in range(5):\n",
    "    with open(f'./models_3/model_{i}.pkl', 'rb') as f:\n",
    "        res  = pickle.load(f)\n",
    "        total_probas_res += cv_predict(res, test_dataloader)\n",
    "total_probas_res /= 5\n",
    "total_probas_v2 = torch.zeros((len(test_dataset.data), 11))\n",
    "for  i in range(5):\n",
    "    with open(f'./models_v2/model_{i}.pkl', 'rb') as f:\n",
    "        res  = pickle.load(f)\n",
    "        total_probas_v2 += cv_predict(res, test_dataloader)\n",
    "total_probas_v2 /= 5\n",
    "total_probas = (total_probas_res + fedyans_probas + total_probas_v2 + total_probas_ef) / 4\n",
    "predicted_classes = torch.argmax(total_probas, dim=1)\n",
    "predicted_classes = np.array([label2color(int(preds)) for preds in predicted_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bb62bfd3-b106-42f9-a6d6-c3f029c64350",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T08:20:41.075997Z",
     "iopub.status.busy": "2022-11-24T08:20:41.075499Z",
     "iopub.status.idle": "2022-11-24T08:20:41.082774Z",
     "shell.execute_reply": "2022-11-24T08:20:41.082406Z",
     "shell.execute_reply.started": "2022-11-24T08:20:41.075978Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1437/1437 [00:00<00:00, 669170.07it/s]\n"
     ]
    }
   ],
   "source": [
    "imgs=[]\n",
    "for img in tqdm(os.listdir(path_to_test)):\n",
    "    if img[0]!='.':\n",
    "        imgs.append(int(os.path.splitext(img)[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b356f4c9-a9c2-4f3f-a7d6-114d890a3c07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T08:20:41.083502Z",
     "iopub.status.busy": "2022-11-24T08:20:41.083321Z",
     "iopub.status.idle": "2022-11-24T08:20:41.085775Z",
     "shell.execute_reply": "2022-11-24T08:20:41.085379Z",
     "shell.execute_reply.started": "2022-11-24T08:20:41.083484Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1075ea6b-fed6-4cf6-a8f8-473e6901a022",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T08:20:41.086727Z",
     "iopub.status.busy": "2022-11-24T08:20:41.086322Z",
     "iopub.status.idle": "2022-11-24T08:20:41.092441Z",
     "shell.execute_reply": "2022-11-24T08:20:41.092088Z",
     "shell.execute_reply.started": "2022-11-24T08:20:41.086708Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>Orange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>Cyan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>Orange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>Cyan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>Grey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>Orange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>Brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>Grey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>Black</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1436 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "720    Green\n",
       "860   Orange\n",
       "683     Cyan\n",
       "519   Orange\n",
       "418     Cyan\n",
       "...      ...\n",
       "1167    Grey\n",
       "954   Orange\n",
       "632    Brown\n",
       "815     Grey\n",
       "1122   Black\n",
       "\n",
       "[1436 rows x 1 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.DataFrame(predicted_classes, index=imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bb95e6cc-a21c-40bf-a85e-b0f2b0a110e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T08:20:41.098678Z",
     "iopub.status.busy": "2022-11-24T08:20:41.098278Z",
     "iopub.status.idle": "2022-11-24T08:20:41.103959Z",
     "shell.execute_reply": "2022-11-24T08:20:41.103629Z",
     "shell.execute_reply.started": "2022-11-24T08:20:41.098660Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df = test_df.sort_index()\n",
    "test_df = test_df.rename(columns={0: test_df[0][0]})\n",
    "test_df.drop([0]).reset_index().drop(columns=['index']).to_csv('4_best.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c1c1d0-869e-4464-8d82-d8fde84d388b",
   "metadata": {},
   "source": [
    "# Private"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cff6de3-82f0-4122-a266-fc9ccfee4968",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T09:00:23.427721Z",
     "iopub.status.busy": "2022-11-24T09:00:23.427326Z",
     "iopub.status.idle": "2022-11-24T09:00:23.652068Z",
     "shell.execute_reply": "2022-11-24T09:00:23.651218Z",
     "shell.execute_reply.started": "2022-11-24T09:00:23.427640Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!tar -xf private_dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cf2cc23-ac93-4a72-97f4-4329b0b7554e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T09:02:05.461659Z",
     "iopub.status.busy": "2022-11-24T09:02:05.461304Z",
     "iopub.status.idle": "2022-11-24T09:02:05.465900Z",
     "shell.execute_reply": "2022-11-24T09:02:05.465139Z",
     "shell.execute_reply.started": "2022-11-24T09:02:05.461630Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e52c39a7-c967-48ab-9778-6c2063eeaea5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T09:02:06.293171Z",
     "iopub.status.busy": "2022-11-24T09:02:06.292814Z",
     "iopub.status.idle": "2022-11-24T09:02:06.303687Z",
     "shell.execute_reply": "2022-11-24T09:02:06.302934Z",
     "shell.execute_reply.started": "2022-11-24T09:02:06.293144Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_transform = A.Compose([\n",
    "                        A.LongestMaxSize(size),\n",
    "                        A.PadIfNeeded(size, size),\n",
    "                        A.CenterCrop(224, 224),\n",
    "                        A.Normalize(),\n",
    "                        ToTensorV2(),\n",
    "])\n",
    "class CarsDatasetTest(torch.utils.data.Dataset):\n",
    "    def __init__(self, path_to_data, transform=False, train=False):\n",
    "        self.path_to_data = path_to_data\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self._get_data_from_path()\n",
    "        if self.transform:\n",
    "            self._add_augmentations()\n",
    "        #self.data = np.array(self.data)\n",
    "\n",
    "    def _get_data_from_path(self):\n",
    "            for img in tqdm(os.listdir(self.path_to_data)):\n",
    "                if img[0]!='.':\n",
    "                    img = cv2.imread(os.path.join(self.path_to_data, img))\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                    label = 0\n",
    "                    self.data.append(img)\n",
    "                    self.labels.append(label)\n",
    "\n",
    "    def _add_augmentations(self):\n",
    "        data = self.data.copy()\n",
    "        del self.data\n",
    "        self.data = []\n",
    "        for img in tqdm(data):\n",
    "            transformed = self.transform(image=img)\n",
    "            img_tensor = transformed['image']\n",
    "            self.data.append(img_tensor)\n",
    "        del data\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24ff6ec7-1e80-4b3e-b9a5-36e957cbb743",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T09:02:12.474639Z",
     "iopub.status.busy": "2022-11-24T09:02:12.474391Z",
     "iopub.status.idle": "2022-11-24T09:02:13.745908Z",
     "shell.execute_reply": "2022-11-24T09:02:13.745161Z",
     "shell.execute_reply.started": "2022-11-24T09:02:12.474622Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1434/1434 [00:00<00:00, 1971.76it/s]\n",
      "100%|██████████| 1434/1434 [00:00<00:00, 2686.53it/s]\n"
     ]
    }
   ],
   "source": [
    "path_to_test = './private_dataset'\n",
    "test_dataset = CarsDatasetTest(path_to_test, transform=test_transform)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5689cef8-44e1-4926-a58b-4bf6d8280325",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T09:02:36.666759Z",
     "iopub.status.busy": "2022-11-24T09:02:36.666527Z",
     "iopub.status.idle": "2022-11-24T09:02:36.670645Z",
     "shell.execute_reply": "2022-11-24T09:02:36.670277Z",
     "shell.execute_reply.started": "2022-11-24T09:02:36.666742Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cv_predict(model, val_dataloader, criterion=None,device=\"cuda:0\"):\n",
    "    model.eval()\n",
    "    predicted_classes = torch.tensor([])\n",
    "    total_loss = 0\n",
    "    n_batchs = 0\n",
    "    first = True\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_dataloader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            #y_preds = model(X_batch)\n",
    "            #total_loss += criterion(y_preds, y_batch)\n",
    "            #y_batch = y_batch.cpu()\n",
    "            if first:\n",
    "                predicted_probas = F.softmax(model(X_batch), dim=1).cpu()\n",
    "                first = False\n",
    "            else:\n",
    "                probas = F.softmax(model(X_batch), dim=1).cpu()\n",
    "                predicted_probas = torch.cat((predicted_probas, probas), dim=0)\n",
    "    return predicted_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a660388-fd15-4a28-a809-24126231b16e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T09:02:39.003395Z",
     "iopub.status.busy": "2022-11-24T09:02:39.003160Z",
     "iopub.status.idle": "2022-11-24T09:02:45.469969Z",
     "shell.execute_reply": "2022-11-24T09:02:45.469481Z",
     "shell.execute_reply.started": "2022-11-24T09:02:39.003379Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.0578e-06, 2.2598e-05, 7.5087e-06,  ..., 2.0078e-07, 2.8801e-07,\n",
       "         2.6676e-07],\n",
       "        [1.1233e-05, 1.6348e-05, 5.3569e-05,  ..., 1.0213e-06, 4.4803e-07,\n",
       "         9.0843e-07],\n",
       "        [4.1196e-06, 8.1225e-06, 9.9880e-01,  ..., 4.2155e-07, 1.8357e-07,\n",
       "         3.4584e-07],\n",
       "        ...,\n",
       "        [1.9156e-06, 6.5778e-07, 1.0315e-06,  ..., 1.3791e-08, 2.3096e-08,\n",
       "         1.5845e-08],\n",
       "        [1.9544e-06, 9.3126e-07, 1.1481e-06,  ..., 3.4035e-07, 1.5612e-07,\n",
       "         1.7659e-07],\n",
       "        [5.4913e-06, 7.5065e-05, 6.6711e-05,  ..., 8.8532e-07, 1.1576e-06,\n",
       "         9.1743e-07]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fedyans_probas = torch.zeros((len(test_dataset.data), 1000))\n",
    "for  i in range(6):\n",
    "    with open(f'./models_1000/model_{i}.pkl', 'rb') as f:\n",
    "        eff  = pickle.load(f)\n",
    "        fedyans_probas += cv_predict(eff, test_dataloader)\n",
    "fedyans_probas /= 6\n",
    "fedyans_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d846abda-1c9a-4c8f-b5bc-007879248620",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T09:02:46.662451Z",
     "iopub.status.busy": "2022-11-24T09:02:46.662238Z",
     "iopub.status.idle": "2022-11-24T09:02:46.665713Z",
     "shell.execute_reply": "2022-11-24T09:02:46.665144Z",
     "shell.execute_reply.started": "2022-11-24T09:02:46.662437Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fedyans_probas = fedyans_probas[:, :11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05cc3a7b-4e7b-4981-b31c-afdfaf2c98f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T09:02:48.260408Z",
     "iopub.status.busy": "2022-11-24T09:02:48.260032Z",
     "iopub.status.idle": "2022-11-24T09:03:08.030247Z",
     "shell.execute_reply": "2022-11-24T09:03:08.029662Z",
     "shell.execute_reply.started": "2022-11-24T09:02:48.260380Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_probas_ef = torch.zeros((len(test_dataset.data), 11))\n",
    "for i in range(5):\n",
    "    with open(f'./models_1/model_{i}.pkl', 'rb') as f:\n",
    "        eff  = pickle.load(f)\n",
    "        total_probas_ef += cv_predict(eff, test_dataloader)\n",
    "total_probas_ef /= 5\n",
    "total_probas_res = torch.zeros((len(test_dataset.data), 11))\n",
    "for i in range(5):\n",
    "    with open(f'./models_3/model_{i}.pkl', 'rb') as f:\n",
    "        res  = pickle.load(f)\n",
    "        total_probas_res += cv_predict(res, test_dataloader)\n",
    "total_probas_res /= 5\n",
    "total_probas_v2 = torch.zeros((len(test_dataset.data), 11))\n",
    "for i in range(5):\n",
    "    with open(f'./models_v2/model_{i}.pkl', 'rb') as f:\n",
    "        res  = pickle.load(f)\n",
    "        total_probas_v2 += cv_predict(res, test_dataloader)\n",
    "total_probas_v2 /= 5\n",
    "total_probas = (total_probas_res + fedyans_probas + total_probas_v2 + total_probas_ef) / 4\n",
    "predicted_classes = torch.argmax(total_probas, dim=1)\n",
    "predicted_classes = np.array([label2color(int(preds)) for preds in predicted_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09443ce8-757d-49f8-a7dd-909f33d01989",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T09:03:08.031841Z",
     "iopub.status.busy": "2022-11-24T09:03:08.031418Z",
     "iopub.status.idle": "2022-11-24T09:03:08.035561Z",
     "shell.execute_reply": "2022-11-24T09:03:08.035091Z",
     "shell.execute_reply.started": "2022-11-24T09:03:08.031818Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1434"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b488a21f-06cc-4171-9522-a0b43a401744",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T09:03:08.036499Z",
     "iopub.status.busy": "2022-11-24T09:03:08.036218Z",
     "iopub.status.idle": "2022-11-24T09:03:08.044427Z",
     "shell.execute_reply": "2022-11-24T09:03:08.043910Z",
     "shell.execute_reply.started": "2022-11-24T09:03:08.036480Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1434/1434 [00:00<00:00, 624767.00it/s]\n"
     ]
    }
   ],
   "source": [
    "imgs=[]\n",
    "for img in tqdm(os.listdir(path_to_test)):\n",
    "    if img[0]!='.':\n",
    "        imgs.append(int(os.path.splitext(img)[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4307bfe-ed1e-4009-a59b-56ad64a10ec8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T09:03:08.045935Z",
     "iopub.status.busy": "2022-11-24T09:03:08.045640Z",
     "iopub.status.idle": "2022-11-24T09:03:08.048322Z",
     "shell.execute_reply": "2022-11-24T09:03:08.047779Z",
     "shell.execute_reply.started": "2022-11-24T09:03:08.045916Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7186304-730c-421a-9f36-1ec635d25d7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T09:03:08.049358Z",
     "iopub.status.busy": "2022-11-24T09:03:08.048947Z",
     "iopub.status.idle": "2022-11-24T09:03:08.070180Z",
     "shell.execute_reply": "2022-11-24T09:03:08.069716Z",
     "shell.execute_reply.started": "2022-11-24T09:03:08.049339Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>Orange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>Brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>Orange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>Grey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>Orange</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1434 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "720   Orange\n",
       "860      Red\n",
       "683    Brown\n",
       "519     Blue\n",
       "418    Green\n",
       "...      ...\n",
       "1167  Orange\n",
       "954    Black\n",
       "632     Grey\n",
       "815      Red\n",
       "1122  Orange\n",
       "\n",
       "[1434 rows x 1 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.DataFrame(predicted_classes, index=imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63bc7d7e-97a5-49ab-840e-f9775a38c298",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T09:03:14.634683Z",
     "iopub.status.busy": "2022-11-24T09:03:14.634474Z",
     "iopub.status.idle": "2022-11-24T09:03:14.643741Z",
     "shell.execute_reply": "2022-11-24T09:03:14.643122Z",
     "shell.execute_reply.started": "2022-11-24T09:03:14.634669Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df = test_df.sort_index()\n",
    "test_df = test_df.rename(columns={0: test_df[0][0]})\n",
    "test_df.drop([0]).reset_index().drop(columns=['index']).to_csv('private.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

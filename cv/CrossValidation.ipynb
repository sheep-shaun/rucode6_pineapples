{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "216c654b-ed9a-4089-842e-16477626b522",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-23T19:56:22.434767Z",
     "iopub.status.busy": "2022-11-23T19:56:22.434541Z",
     "iopub.status.idle": "2022-11-23T19:56:24.027098Z",
     "shell.execute_reply": "2022-11-23T19:56:24.026564Z",
     "shell.execute_reply.started": "2022-11-23T19:56:22.434748Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (1.23.5)\n",
      "Requirement already satisfied: hyperopt in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (0.2.7)\n",
      "Requirement already satisfied: catboost in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (1.1.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (1.5.1)\n",
      "Requirement already satisfied: geopy in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (2.3.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (3.6.2)\n",
      "Requirement already satisfied: shap in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (0.41.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (1.8.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (4.64.1)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (1.13.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (0.14.0)\n",
      "Requirement already satisfied: albumentations in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (1.3.0)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (4.6.0.66)\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 14)) (0.12.1)\n",
      "Requirement already satisfied: typing in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 15)) (3.7.4.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from hyperopt->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /opt/conda/lib/python3.10/site-packages (from hyperopt->-r requirements.txt (line 2)) (2.8.8)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.10/site-packages (from hyperopt->-r requirements.txt (line 2)) (0.18.2)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.10/site-packages (from hyperopt->-r requirements.txt (line 2)) (2.2.0)\n",
      "Requirement already satisfied: py4j in /opt/conda/lib/python3.10/site-packages (from hyperopt->-r requirements.txt (line 2)) (0.10.9.7)\n",
      "Requirement already satisfied: plotly in /opt/conda/lib/python3.10/site-packages (from catboost->-r requirements.txt (line 3)) (5.11.0)\n",
      "Requirement already satisfied: graphviz in /opt/conda/lib/python3.10/site-packages (from catboost->-r requirements.txt (line 3)) (0.20.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 4)) (2022.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 4)) (2.8.2)\n",
      "Requirement already satisfied: geographiclib<3,>=1.52 in /opt/conda/lib/python3.10/site-packages (from geopy->-r requirements.txt (line 5)) (2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 6)) (21.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 6)) (1.0.6)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 6)) (4.38.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 6)) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 6)) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 6)) (9.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 6)) (0.11.0)\n",
      "Requirement already satisfied: numba in /opt/conda/lib/python3.10/site-packages (from shap->-r requirements.txt (line 7)) (0.56.4)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from shap->-r requirements.txt (line 7)) (1.1.3)\n",
      "Requirement already satisfied: slicer==0.0.7 in /opt/conda/lib/python3.10/site-packages (from shap->-r requirements.txt (line 7)) (0.0.7)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 10)) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 10)) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 10)) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 10)) (8.5.0.96)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 10)) (4.3.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->-r requirements.txt (line 10)) (65.3.0)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->-r requirements.txt (line 10)) (0.37.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision->-r requirements.txt (line 11)) (2.28.1)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from albumentations->-r requirements.txt (line 12)) (6.0)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in /opt/conda/lib/python3.10/site-packages (from albumentations->-r requirements.txt (line 12)) (0.19.3)\n",
      "Requirement already satisfied: qudida>=0.0.4 in /opt/conda/lib/python3.10/site-packages (from albumentations->-r requirements.txt (line 12)) (0.0.4)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in /opt/conda/lib/python3.10/site-packages (from albumentations->-r requirements.txt (line 12)) (4.6.0.66)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations->-r requirements.txt (line 12)) (1.4.1)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations->-r requirements.txt (line 12)) (2.22.4)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations->-r requirements.txt (line 12)) (2022.10.10)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->shap->-r requirements.txt (line 7)) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->shap->-r requirements.txt (line 7)) (1.2.0)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba->shap->-r requirements.txt (line 7)) (0.39.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly->catboost->-r requirements.txt (line 3)) (8.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->-r requirements.txt (line 11)) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->-r requirements.txt (line 11)) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->-r requirements.txt (line 11)) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->-r requirements.txt (line 11)) (3.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "451783ab-3c9b-4f22-ac7c-74f99971a6b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T09:01:42.715179Z",
     "iopub.status.busy": "2022-11-24T09:01:42.714882Z",
     "iopub.status.idle": "2022-11-24T09:01:43.362885Z",
     "shell.execute_reply": "2022-11-24T09:01:43.362306Z",
     "shell.execute_reply.started": "2022-11-24T09:01:42.715157Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c15afc4b-482e-4622-bfc7-86240db08c00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T09:01:43.363975Z",
     "iopub.status.busy": "2022-11-24T09:01:43.363782Z",
     "iopub.status.idle": "2022-11-24T09:01:44.319478Z",
     "shell.execute_reply": "2022-11-24T09:01:44.318945Z",
     "shell.execute_reply.started": "2022-11-24T09:01:43.363962Z"
    },
    "id": "ouwPzoapsv4V",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "import albumentations as A\n",
    "import cv2\n",
    "from tqdm.auto import tqdm\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.cuda.amp import GradScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9766ea04-b291-4dc7-88f5-1dca816c528c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T09:01:44.320246Z",
     "iopub.status.busy": "2022-11-24T09:01:44.320013Z",
     "iopub.status.idle": "2022-11-24T09:01:44.465185Z",
     "shell.execute_reply": "2022-11-24T09:01:44.464642Z",
     "shell.execute_reply.started": "2022-11-24T09:01:44.320232Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!tar -xf car_color_dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7c82d5-8bc1-4c88-b750-02daa2d7a1ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "953ee884-bee1-4d64-b3e1-55398d433677",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-21T10:58:16.042221Z",
     "iopub.status.busy": "2022-11-21T10:58:16.041986Z",
     "iopub.status.idle": "2022-11-21T10:58:16.044722Z",
     "shell.execute_reply": "2022-11-21T10:58:16.044306Z",
     "shell.execute_reply.started": "2022-11-21T10:58:16.042208Z"
    },
    "id": "I9IUK5-DCT4E",
    "tags": []
   },
   "source": [
    "# CrossVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2288e271-0c43-452a-b70a-21080085112f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T09:01:44.764004Z",
     "iopub.status.busy": "2022-11-24T09:01:44.763689Z",
     "iopub.status.idle": "2022-11-24T09:01:44.777207Z",
     "shell.execute_reply": "2022-11-24T09:01:44.776477Z",
     "shell.execute_reply.started": "2022-11-24T09:01:44.763981Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "size = 256\n",
    "def color2label(color):\n",
    "    c2l = {\n",
    "        'Black': 0,\n",
    "        'Blue': 1,\n",
    "        'Brown': 2,\n",
    "        'Cyan': 3,\n",
    "        'Green': 4,\n",
    "        'Grey': 5,\n",
    "        'Orange': 6,\n",
    "        'Red': 7,\n",
    "        'Violet': 8,\n",
    "        'White': 9,\n",
    "        'Yellow': 10\n",
    "    }\n",
    "\n",
    "    return c2l[color]\n",
    "def label2color(label):\n",
    "    c2l = {\n",
    "        'Black': 0,\n",
    "        'Blue': 1,\n",
    "        'Brown': 2,\n",
    "        'Cyan': 3,\n",
    "        'Green': 4,\n",
    "        'Grey': 5,\n",
    "        'Orange': 6,\n",
    "        'Red': 7,\n",
    "        'Violet': 8,\n",
    "        'White': 9,\n",
    "        'Yellow': 10\n",
    "    }\n",
    "    l2c = {v: k for k, v in c2l.items()}\n",
    "    return l2c[label]\n",
    "def label_weight(label):\n",
    "    lw = {\n",
    "        0: 2,\n",
    "        1: 3,\n",
    "        2: 8,\n",
    "        3: 3,\n",
    "        4: 3,\n",
    "        5: 2,\n",
    "        6: 1,\n",
    "        7: 1,\n",
    "        8: 8,\n",
    "        9: 2,\n",
    "        10: 2\n",
    "    }\n",
    "\n",
    "    return lw[label]\n",
    "class CarsDataset3(torch.utils.data.Dataset):\n",
    "    def __init__(self, path_to_data, transform=False, train=False):\n",
    "        self.path_to_data = path_to_data\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self._get_data_from_path()\n",
    "        self.data = np.array(self.data)\n",
    "        self.labels = np.array(self.labels)\n",
    "\n",
    "    def _get_data_from_path(self):\n",
    "        for folder in tqdm(os.listdir(self.path_to_data)):\n",
    "            img_folder = os.path.join(self.path_to_data, folder)\n",
    "            for img in os.listdir(img_folder):\n",
    "                img = cv2.imread(os.path.join(img_folder, img))\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                label = color2label(folder)\n",
    "                size = 256\n",
    "                transform = A.Compose([\n",
    "                                        A.LongestMaxSize(size),\n",
    "                                        A.PadIfNeeded(size, size),\n",
    "                                        A.CenterCrop(224, 224)])\n",
    "                transformed = transform(image=img)\n",
    "                img_tensor = transformed['image']\n",
    "                self.data.append(img_tensor)\n",
    "                self.labels.append(label)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86f6364d-1d03-4b3b-9714-d53521d37128",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T07:47:54.054236Z",
     "iopub.status.busy": "2022-11-24T07:47:54.054029Z",
     "iopub.status.idle": "2022-11-24T07:47:56.428758Z",
     "shell.execute_reply": "2022-11-24T07:47:56.428010Z",
     "shell.execute_reply.started": "2022-11-24T07:47:54.054217Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25a8734488934b0285cd6204a304ec18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path_to_train = './train'\n",
    "train_dataset = CarsDataset3(path_to_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea97ad15-695f-4e56-9654-c73bbc15c9fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T09:01:53.074106Z",
     "iopub.status.busy": "2022-11-24T09:01:53.073695Z",
     "iopub.status.idle": "2022-11-24T09:01:53.099824Z",
     "shell.execute_reply": "2022-11-24T09:01:53.099186Z",
     "shell.execute_reply.started": "2022-11-24T09:01:53.074077Z"
    },
    "id": "m9vMjcYai5mR",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.optim\n",
    "\n",
    "from typing import TYPE_CHECKING, Any, Callable, Optional\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from torch.optim.optimizer import _params_t\n",
    "else:\n",
    "    _params_t = Any\n",
    "\n",
    "class MADGRAD(torch.optim.Optimizer):\n",
    "    def __init__(\n",
    "        self, params: _params_t, lr: float = 1e-2, momentum: float = 0.9, \n",
    "        weight_decay: float = 0, eps: float = 1e-6, decouple_decay=False,\n",
    "    ):\n",
    "        if momentum < 0 or momentum >= 1:\n",
    "            raise ValueError(f\"Momentum {momentum} must be in the range [0,1)\")\n",
    "        if lr <= 0:\n",
    "            raise ValueError(f\"Learning rate {lr} must be positive\")\n",
    "        if weight_decay < 0:\n",
    "            raise ValueError(f\"Weight decay {weight_decay} must be non-negative\")\n",
    "        if eps < 0:\n",
    "            raise ValueError(f\"Eps must be non-negative\")\n",
    "\n",
    "        defaults = dict(lr=lr, eps=eps, momentum=momentum, \n",
    "                        weight_decay=weight_decay, decouple_decay=decouple_decay)\n",
    "        super().__init__(params, defaults)\n",
    "\n",
    "    @property\n",
    "    def supports_memory_efficient_fp16(self) -> bool:\n",
    "        return False\n",
    "\n",
    "    @property\n",
    "    def supports_flat_params(self) -> bool:\n",
    "        return True\n",
    "\n",
    "    def step(self, closure: Optional[Callable[[], float]] = None) -> Optional[float]:\n",
    "        \"\"\"Performs a single optimization step.\n",
    "        Arguments:\n",
    "            closure (callable, optional): A closure that reevaluates the model\n",
    "                and returns the loss.\n",
    "        \"\"\"\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        # step counter must be stored in state to ensure correct behavior under\n",
    "        # optimizer sharding\n",
    "        if 'k' not in self.state:\n",
    "            self.state['k'] = torch.tensor([0], dtype=torch.long)\n",
    "        k = self.state['k'].item()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            eps = group[\"eps\"]\n",
    "            lr = group[\"lr\"] + eps\n",
    "            decay = group[\"weight_decay\"]\n",
    "            momentum = group[\"momentum\"]\n",
    "            decouple_decay = group[\"decouple_decay\"]\n",
    "\n",
    "            ck = 1 - momentum\n",
    "            lamb = lr * math.pow(k + 1, 0.5)\n",
    "\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data\n",
    "                state = self.state[p]\n",
    "\n",
    "                if \"grad_sum_sq\" not in state:\n",
    "                    state[\"grad_sum_sq\"] = torch.zeros_like(p.data).detach()\n",
    "                    state[\"s\"] = torch.zeros_like(p.data).detach()\n",
    "                    if momentum != 0:\n",
    "                        state[\"x0\"] = torch.clone(p.data).detach()\n",
    "\n",
    "                if momentum != 0.0 and grad.is_sparse:\n",
    "                    raise RuntimeError(\"momentum != 0 is not compatible with sparse gradients\")\n",
    "\n",
    "                grad_sum_sq = state[\"grad_sum_sq\"]\n",
    "                s = state[\"s\"]\n",
    "\n",
    "                # Apply weight decay\n",
    "                if decay != 0 and not decouple_decay:\n",
    "                    if grad.is_sparse:\n",
    "                        raise RuntimeError(\"weight_decay option is not compatible with sparse gradients\")\n",
    "\n",
    "                    grad.add_(p.data, alpha=decay)\n",
    "\n",
    "                if grad.is_sparse:\n",
    "                    grad = grad.coalesce()\n",
    "                    grad_val = grad._values()\n",
    "\n",
    "                    p_masked = p.sparse_mask(grad)\n",
    "                    grad_sum_sq_masked = grad_sum_sq.sparse_mask(grad)\n",
    "                    s_masked = s.sparse_mask(grad)\n",
    "\n",
    "                    # Compute x_0 from other known quantities\n",
    "                    rms_masked_vals = grad_sum_sq_masked._values().pow(1 / 3).add_(eps)\n",
    "                    x0_masked_vals = p_masked._values().addcdiv(s_masked._values(), rms_masked_vals, value=1)\n",
    "\n",
    "                    # Dense + sparse op\n",
    "                    grad_sq = grad * grad\n",
    "                    grad_sum_sq.add_(grad_sq, alpha=lamb)\n",
    "                    grad_sum_sq_masked.add_(grad_sq, alpha=lamb)\n",
    "\n",
    "                    rms_masked_vals = grad_sum_sq_masked._values().pow_(1 / 3).add_(eps)\n",
    "\n",
    "                    if eps == 0:\n",
    "                        rms_masked_vals[rms_masked_vals == 0] = float('inf')\n",
    "\n",
    "                    s.add_(grad, alpha=lamb)\n",
    "                    s_masked._values().add_(grad_val, alpha=lamb)\n",
    "\n",
    "                    # update masked copy of p\n",
    "                    p_kp1_masked_vals = x0_masked_vals.addcdiv(s_masked._values(), rms_masked_vals, value=-1)\n",
    "                    # Copy updated masked p to dense p using an add operation\n",
    "                    p_masked._values().add_(p_kp1_masked_vals, alpha=-1)\n",
    "                    p.data.add_(p_masked, alpha=-1)\n",
    "                else:\n",
    "                    if momentum == 0:\n",
    "                        # Compute x_0 from other known quantities\n",
    "                        rms = grad_sum_sq.pow(1 / 3).add_(eps)\n",
    "                        x0 = p.data.addcdiv(s, rms, value=1)\n",
    "                    else:\n",
    "                        x0 = state[\"x0\"]\n",
    "\n",
    "                    # Accumulate second moments\n",
    "                    grad_sum_sq.addcmul_(grad, grad, value=lamb)\n",
    "                    rms = grad_sum_sq.pow(1 / 3).add_(eps)\n",
    "\n",
    "                    if eps == 0:\n",
    "                        rms[rms == 0] = float('inf')\n",
    "\n",
    "                    # Update s\n",
    "                    s.data.add_(grad, alpha=lamb)\n",
    "\n",
    "                    if decay != 0 and decouple_decay:\n",
    "                        p_old = p.data.clone()\n",
    "\n",
    "                    # Step\n",
    "                    if momentum == 0:\n",
    "                        p.data.copy_(x0.addcdiv(s, rms, value=-1))\n",
    "                    else:\n",
    "                        z = x0.addcdiv(s, rms, value=-1)\n",
    "\n",
    "                        # p is a moving average of z\n",
    "                        p.data.mul_(1 - ck).add_(z, alpha=ck)\n",
    "                    \n",
    "                    if decay != 0 and decouple_decay:\n",
    "                        p.data.add_(p_old, alpha=-lr*decay)\n",
    "\n",
    "\n",
    "        self.state['k'] += 1\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe2774f6-559c-49c8-bd0a-841b5d5c103d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T09:01:53.368902Z",
     "iopub.status.busy": "2022-11-24T09:01:53.368552Z",
     "iopub.status.idle": "2022-11-24T09:01:53.382550Z",
     "shell.execute_reply": "2022-11-24T09:01:53.381910Z",
     "shell.execute_reply.started": "2022-11-24T09:01:53.368874Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_dataloader, criterion, optimizer, scaler, device=\"cuda:0\"):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "    n_batchs = 0\n",
    "    for X_batch, y_batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "            y_preds = model(X_batch)\n",
    "            loss = criterion(y_preds, y_batch)\n",
    "            total_loss += loss\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total_accuracy += accuracy_score(y_batch.cpu().numpy(), torch.argmax(y_preds, dim=-1).detach().cpu().numpy())\n",
    "        n_batchs += 1\n",
    "    total_accuracy /= n_batchs\n",
    "    total_loss /= n_batchs\n",
    "    return total_accuracy, total_loss\n",
    "\n",
    "def predict(model, val_dataloader, criterion, device=\"cuda:0\"):\n",
    "    model.eval()\n",
    "    predicted_classes = torch.tensor([])\n",
    "    true_classes = torch.tensor([])\n",
    "    total_loss = 0\n",
    "    n_batchs = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_dataloader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            y_preds = model(X_batch)\n",
    "            total_loss += criterion(y_preds, y_batch)\n",
    "            y_batch = y_batch.cpu()\n",
    "            predicts = model(X_batch)\n",
    "            predicts = torch.argmax(predicts, dim=1).cpu()\n",
    "            predicted_classes = torch.cat((predicted_classes, predicts), dim=-1)\n",
    "            true_classes = torch.cat((true_classes, y_batch), dim=-1)\n",
    "            n_batchs += 1\n",
    "    total_loss /= n_batchs\n",
    "    return total_loss, predicted_classes.numpy(), true_classes.numpy()\n",
    "\n",
    "def train(model, train_dataloader, val_dataloader, criterion, optimizer, scaler, lr_scheduler, device=\"cuda:0\", n_epochs=10):\n",
    "    model.to(device)\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        train_acc, train_loss = train_one_epoch(model, train_dataloader, criterion, optimizer, scaler, device=device)\n",
    "        if lr_scheduler is not None: \n",
    "            lr_scheduler.step()\n",
    "        val_loss, predicted_classes, true_classes = predict(model, val_dataloader, criterion, device=device)\n",
    "        val_acc = accuracy_score(true_classes, predicted_classes)\n",
    "        print(f'Train Loss:{train_loss} Train Accuracy:{train_acc}')\n",
    "        print(f'Val Loss:{val_loss} Val Accuracy:{val_acc} ')\n",
    "        del true_classes, predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e34be575-868a-4404-9441-32d071f30f97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T09:01:56.825166Z",
     "iopub.status.busy": "2022-11-24T09:01:56.824933Z",
     "iopub.status.idle": "2022-11-24T09:01:56.844580Z",
     "shell.execute_reply": "2022-11-24T09:01:56.844064Z",
     "shell.execute_reply.started": "2022-11-24T09:01:56.825148Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/albumentations/augmentations/dropout/cutout.py:49: FutureWarning: Cutout has been deprecated. Please use CoarseDropout\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torchvision.models import efficientnet_v2_l\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "train_transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    #A.Blur(blur_limit=2.5, p=0.3),\n",
    "    A.OneOf([\n",
    "            A.CLAHE(clip_limit=2, p=0.75),\n",
    "            A.RandomBrightnessContrast(p=0.75),\n",
    "            A.ImageCompression(quality_lower=90, quality_upper=100, p=0.75),\n",
    "        ], p=0.5),\n",
    "    A.OneOf([\n",
    "                A.Blur(blur_limit=2.5, p=0.75),\n",
    "                A.MotionBlur(blur_limit=(3, 5), p=0.75),\n",
    "            ], p=0.5),\n",
    "    A.OneOf([\n",
    "                A.Cutout(num_holes=12, max_h_size=21, max_w_size=21, p=0.75),\n",
    "                A.Cutout(num_holes=6, max_h_size=42, max_w_size=42, p=0.75),\n",
    "            ], p=0.5),\n",
    "])\n",
    "val_transform = A.Compose([\n",
    "    A.Normalize(), \n",
    "    ToTensorV2()])\n",
    "class cv_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, labels, transform, second_transform=None, train=False):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform  = transform\n",
    "        self.second_transform = second_transform\n",
    "        self.train = train\n",
    "        self._add_augmentations()\n",
    "        if self.train:\n",
    "            #self._add_second_aug()\n",
    "            data = self.data.copy()\n",
    "            labels = self.labels.copy()\n",
    "            del self.data, self.labels\n",
    "            self.data = []\n",
    "            self.labels = []\n",
    "            for i in tqdm(range(len(data))):\n",
    "                img = data[i]\n",
    "                label = labels[i]\n",
    "                transforms = A.Compose([\n",
    "                                A.Normalize(), \n",
    "                                ToTensorV2()])\n",
    "                transformed = transforms(image=img)\n",
    "                img_tensor = transformed['image']\n",
    "                self.data.append(img_tensor)\n",
    "                self.labels.append(label)\n",
    "        \n",
    "    def _add_augmentations(self):\n",
    "        data = self.data.copy()\n",
    "        labels = self.labels.copy()\n",
    "        del self.data, self.labels\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        for i in tqdm(range(len(data))):\n",
    "            img = data[i]\n",
    "            label = labels[i]\n",
    "            weight =  1\n",
    "            for j in range(weight):\n",
    "                transformed = self.transform(image=img)\n",
    "                img_tensor = transformed['image']\n",
    "                self.data.append(img_tensor)\n",
    "                self.labels.append(label)\n",
    "                \n",
    "    def _add_second_aug(self):\n",
    "        data = self.data.copy()\n",
    "        labels = self.labels.copy()\n",
    "        for i in tqdm(range(len(data))):\n",
    "            img = data[i]\n",
    "            label = labels[i]\n",
    "            transformed = self.second_transform(image=img)\n",
    "            img_tensor = transformed['image']\n",
    "            self.data.append(img_tensor)\n",
    "            self.labels.append(label)\n",
    "        del data, labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "    \n",
    "def crossval(dataset, train_transform=train_transform, val_transform=val_transform,second_transform=None, n_folds=6):\n",
    "    kf = KFold(n_splits=n_folds, random_state=42, shuffle=True)\n",
    "    kf.get_n_splits(dataset.data)\n",
    "    i = 0\n",
    "    for train_index, test_index in kf.split(dataset.data, dataset.labels):\n",
    "        X_train, y_train = dataset[train_index]\n",
    "        X_test, y_test = dataset[test_index]\n",
    "        fold_train = cv_dataset(X_train, y_train, train_transform, train=True)\n",
    "        fold_val = cv_dataset(X_test, y_test, val_transform, train=False)\n",
    "        train_dataloader = DataLoader(fold_train, batch_size=16, drop_last=True, shuffle=True)\n",
    "        val_dataloader = DataLoader(fold_val , batch_size=16, drop_last=True, shuffle=True)\n",
    "        device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "        model = efficientnet_v2_l(weights='IMAGENET1K_V1')\n",
    "        model.classifier = nn.Linear(1280, 11)\n",
    "        model.to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = MADGRAD(model.parameters(), 5e-5, weight_decay=4e-4, momentum=0.9)\n",
    "        scaler = GradScaler()\n",
    "        lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=15, eta_min=3e-7, last_epoch=- 1, verbose=False)\n",
    "        train(model, train_dataloader, val_dataloader, criterion, optimizer, scaler, lr_scheduler, device=\"cuda:0\", n_epochs=15)\n",
    "        with open(f'./models/model_{i}.pkl', 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "        del model, train_dataloader, val_dataloader, fold_train, fold_val\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e71147eb-bc18-4837-93ca-c4847f08bc37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T08:34:52.987047Z",
     "iopub.status.busy": "2022-11-24T08:34:52.986682Z",
     "iopub.status.idle": "2022-11-24T08:54:02.079384Z",
     "shell.execute_reply": "2022-11-24T08:54:02.078721Z",
     "shell.execute_reply.started": "2022-11-24T08:34:52.987018Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3041/3041 [00:02<00:00, 1300.18it/s]\n",
      "100%|██████████| 3041/3041 [00:00<00:00, 3606.22it/s]\n",
      "100%|██████████| 761/761 [00:00<00:00, 4774.65it/s]\n",
      "Downloading: \"https://download.pytorch.org/models/efficientnet_v2_l-59c71312.pth\" to /home/jovyan/.cache/torch/hub/checkpoints/efficientnet_v2_l-59c71312.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36c99b532f3046fb8c59293fc0116680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/455M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [01:13<17:08, 73.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:0.662440836429596 Train Accuracy:0.8075657894736842\n",
      "Val Loss:0.15683378279209137 Val Accuracy:0.9601063829787234 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [02:26<15:54, 73.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:0.2029748111963272 Train Accuracy:0.9411184210526315\n",
      "Val Loss:0.1478148102760315 Val Accuracy:0.949468085106383 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [03:40<14:44, 73.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:0.10965021699666977 Train Accuracy:0.9703947368421053\n",
      "Val Loss:0.17788097262382507 Val Accuracy:0.9468085106382979 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 4/15 [04:55<13:32, 73.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:0.09355127811431885 Train Accuracy:0.9723684210526315\n",
      "Val Loss:0.16180621087551117 Val Accuracy:0.9521276595744681 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5/15 [06:09<12:19, 73.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:0.08108971267938614 Train Accuracy:0.9759868421052632\n",
      "Val Loss:0.14128489792346954 Val Accuracy:0.9627659574468085 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [07:22<11:03, 73.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:0.04029504209756851 Train Accuracy:0.9881578947368421\n",
      "Val Loss:0.12815174460411072 Val Accuracy:0.9601063829787234 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [08:35<09:47, 73.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:0.033196885138750076 Train Accuracy:0.9911184210526316\n",
      "Val Loss:0.14873477816581726 Val Accuracy:0.9521276595744681 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [09:48<08:32, 73.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:0.04452323168516159 Train Accuracy:0.9878289473684211\n",
      "Val Loss:0.10362839698791504 Val Accuracy:0.9720744680851063 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [11:00<07:18, 73.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:0.025989757850766182 Train Accuracy:0.9930921052631579\n",
      "Val Loss:0.08661960065364838 Val Accuracy:0.976063829787234 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [12:13<06:03, 72.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:0.009963945485651493 Train Accuracy:0.9970394736842105\n",
      "Val Loss:0.11227350682020187 Val Accuracy:0.973404255319149 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [13:25<04:50, 72.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:0.008681477047502995 Train Accuracy:0.9976973684210526\n",
      "Val Loss:0.11113952845335007 Val Accuracy:0.9680851063829787 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [14:37<03:37, 72.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:0.004217221401631832 Train Accuracy:0.9993421052631579\n",
      "Val Loss:0.11568078398704529 Val Accuracy:0.9694148936170213 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 13/15 [15:50<02:24, 72.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:0.006944369524717331 Train Accuracy:0.9980263157894737\n",
      "Val Loss:0.11981259286403656 Val Accuracy:0.964095744680851 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 14/15 [17:02<01:12, 72.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:0.003609290812164545 Train Accuracy:1.0\n",
      "Val Loss:0.11569105088710785 Val Accuracy:0.9707446808510638 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [18:15<00:00, 73.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:0.0020041191019117832 Train Accuracy:1.0\n",
      "Val Loss:0.11032257229089737 Val Accuracy:0.9667553191489362 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3041/3041 [00:02<00:00, 1342.12it/s]\n",
      "100%|██████████| 3041/3041 [00:00<00:00, 4662.07it/s]\n",
      "100%|██████████| 761/761 [00:00<00:00, 5400.41it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 23.68 GiB total capacity; 6.95 GiB already allocated; 28.56 MiB free; 7.00 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcrossval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_transform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_transform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_folds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [40], line 107\u001b[0m, in \u001b[0;36mcrossval\u001b[0;34m(dataset, train_transform, val_transform, second_transform, n_folds)\u001b[0m\n\u001b[1;32m    105\u001b[0m scaler \u001b[38;5;241m=\u001b[39m GradScaler()\n\u001b[1;32m    106\u001b[0m lr_scheduler \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mCosineAnnealingLR(optimizer, T_max\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m, eta_min\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3e-7\u001b[39m, last_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 107\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda:0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./models/model_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    109\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(model, f)\n",
      "Cell \u001b[0;32mIn [7], line 45\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, val_dataloader, criterion, optimizer, scaler, lr_scheduler, device, n_epochs)\u001b[0m\n\u001b[1;32m     43\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(n_epochs)):\n\u001b[0;32m---> 45\u001b[0m     train_acc, train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lr_scheduler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \n\u001b[1;32m     47\u001b[0m         lr_scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[0;32mIn [7], line 13\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, train_dataloader, criterion, optimizer, scaler, device)\u001b[0m\n\u001b[1;32m     11\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(y_preds, y_batch)\n\u001b[1;32m     12\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[0;32m---> 13\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m scaler\u001b[38;5;241m.\u001b[39mstep(optimizer)\n\u001b[1;32m     15\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 23.68 GiB total capacity; 6.95 GiB already allocated; 28.56 MiB free; 7.00 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "crossval(train_dataset, train_transform=train_transform, val_transform=val_transform, n_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8a7763b-a1d0-46bc-8d7e-96648659cc7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T08:16:49.253864Z",
     "iopub.status.busy": "2022-11-24T08:16:49.253505Z",
     "iopub.status.idle": "2022-11-24T08:16:49.337152Z",
     "shell.execute_reply": "2022-11-24T08:16:49.336748Z",
     "shell.execute_reply.started": "2022-11-24T08:16:49.253835Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b370e60-1720-4fe2-a0c6-298aaf7535c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T08:16:49.574542Z",
     "iopub.status.busy": "2022-11-24T08:16:49.574332Z",
     "iopub.status.idle": "2022-11-24T08:16:49.611833Z",
     "shell.execute_reply": "2022-11-24T08:16:49.611481Z",
     "shell.execute_reply.started": "2022-11-24T08:16:49.574528Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
